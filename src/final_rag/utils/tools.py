import sys
from pathlib import Path
# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent))

import logging
from langchain_core.tools import tool
from pydantic import BaseModel, Field
from utils.embeddings_utils import call_dashscope_once
from pymilvus import AnnSearchRequest, WeightedRanker, RRFRanker, MilvusClient, Function, FunctionType
from env_utils import CONTEXT_COLLECTION_NAME, MILVUS_URI
from llm_utils import qwen3_max

logger = logging.getLogger(__name__)

client=MilvusClient(uri=MILVUS_URI, user='root', password='Milvus')

class WebSearchInput(BaseModel):
    query: str = Field(description="The search query to look up on the internet")

@tool('web_search', args_schema=WebSearchInput, description='Search the internet for real-time public information')
def web_search(query: str) -> str:
    """
    Search the internet for real-time information. Use when you need current events or up-to-date facts.

    Args:
        query: The search query

    Returns:
        str: Search results from the internet
    """
    logger.info(f"Web search for: {query}")
    response = qwen3_max.invoke(f"Search web and answer: {query}")
    return response.content
    

@tool('search_context', parse_docstring=True)
def search_context(query: str=None, user_name: str=None) -> str:
    """
    æ ¹æ®ç”¨æˆ·çš„è¾“å…¥ï¼Œä»ä¸Šä¸‹æ–‡æ•°æ®åº“æ£€ç´¢æŸ¥è¯¢ç›¸å…³çš„å†å²ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¹¶ç»™å‡ºæ­£ç¡®çš„å›ç­”

    Args:
        query: ç”¨æˆ·çš„è¾“å…¥
        user_name: å½“å‰çš„ç”¨æˆ·å

    Returns:
        str: æŸ¥è¯¢åˆ°çš„å†å²ä¸Šä¸‹æ–‡ä¿¡æ¯
    """
    # 1.æ„é€ ç¬¦åˆ DashScopeï¼ˆé€šä¹‰åƒé—® APIï¼‰æ–‡æœ¬åµŒå…¥æ¥å£ è¦æ±‚çš„è¾“å…¥æ ¼å¼ DashScope çš„ text-embedding API é€šå¸¸è¦æ±‚è¾“å…¥æ˜¯ List[Dict]
    input_data = [{'text': query}]
    # 2.å‘ DashScope å‘é€è¯·æ±‚ï¼Œè·å– query çš„ ç¨ å¯†å‘é‡åµŒå…¥ï¼ˆcontext_embeddingï¼‰ã€‚
    ok, context_embedding, status, retry_after = call_dashscope_once(input_data)
    filter_expr = None
    if user_name:
        filter_expr = f"user == '{user_name}'"      # è¿‡æ»¤æŸ¥è¯¢æŒ‡å®šç”¨æˆ· æ ¹æ®schemaä¸­è‡ªå®šä¹‰çš„schemaå†³å®š

    # æ··åˆæ£€ç´¢
    # æ¯ä¸ª AnnSearchRequest ä»£è¡¨é’ˆå¯¹ç‰¹å®šå‘é‡å­—æ®µçš„åŸºç¡€ ANN æœç´¢è¯·æ±‚ ä¸ç®¡æ˜¯å›¾ç‰‡è¿˜æ˜¯æ–‡æœ¬ï¼Œæˆ‘ä»¬éƒ½å¯ä»¥ç»Ÿä¸€è½¬åŒ–ä¸ºdenseå‘é‡
    dense_search_params = {"metric_type": "COSINE", "params": {"nprobe": 10}}
    dense_req = AnnSearchRequest(
        data = [context_embedding],
        anns_field = "context_dense",
        limit = 5,
        param = dense_search_params,
        expr=filter_expr # è¿‡æ»¤ç”¨æˆ·åè¿›è¡Œæ£€ç´¢
    )

    sparse_search_params = {"metric_type": "BM25", "params": {'drop_ratio_search': 0.2}}
    sparse_req = AnnSearchRequest(
        data = [query],
        anns_field = "context_sparse",         # collection ä¸­å­˜å‚¨ç¨€ç–å‘é‡ï¼ˆå¦‚ SPLADE æˆ– BM25 ç”Ÿæˆçš„ï¼‰çš„å­—æ®µ
        limit = 5,
        param = sparse_search_params,
        expr=filter_expr             # è¿‡æ»¤ç”¨æˆ·åè¿›è¡Œæ£€ç´¢
    )

    # åœ¨æ··åˆæœç´¢ä¸­ï¼Œé‡æ’åºæ˜¯ä¸€ä¸ªå…³é”®æ­¥éª¤ï¼Œå®ƒæ•´åˆäº†æ¥è‡ªå¤šä¸ªå‘é‡æœç´¢çš„ç»“æœï¼Œä»¥ç¡®ä¿æœ€ç»ˆè¾“å‡ºæ˜¯æœ€ç›¸å…³å’Œæœ€å‡†ç¡®çš„
    
    # æ–¹æ¡ˆ1: RRF Ranker (Reciprocal Rank Fusion) - è‡ªåŠ¨å½’ä¸€åŒ–ä¸åŒç±»å‹çš„åˆ†æ•°
    # ranker = RRFRanker(k=60)  # kå€¼è¶Šå¤§ï¼Œæ’åé åçš„ç»“æœå½±å“è¶Šå°
    
    # æ–¹æ¡ˆ2: Weighted Ranker + å½’ä¸€åŒ– (å½“å‰ä½¿ç”¨)
    # ä½¿ç”¨ arctan å½’ä¸€åŒ–ç¡®ä¿ä¸åŒåº¦é‡æ ‡å‡†ï¼ˆCOSINE å’Œ BM25ï¼‰çš„åˆ†æ•°å¯æ¯”
    ranker = Function(
        name="weighted_ranker",
        input_field_names=[],  # é‡æ’åºå‡½æ•°å¿…é¡»ä¸ºç©ºåˆ—è¡¨
        function_type=FunctionType.RERANK,
        params={
            "reranker": "weighted",
            "weights": [0.8, 1],  # [denseæƒé‡, sparseæƒé‡]ï¼Œdenseæ£€ç´¢æƒé‡æ›´é«˜
            "norm_score": True  # å¯ç”¨å½’ä¸€åŒ–ï¼Œä½¿ç”¨arctanå‡½æ•°å°†åˆ†æ•°å½’ä¸€åŒ–åˆ°ç›¸è¿‘èŒƒå›´
        }
    )
    
    logger.info(f"ğŸ’¬ å¼€å§‹æ£€ç´¢å†å²å¯¹è¯ä¸Šä¸‹æ–‡... (user={user_name}, query={query[:30]}...)")

    res = client.hybrid_search(
        collection_name=CONTEXT_COLLECTION_NAME,
        reqs = [dense_req, sparse_req],
        ranker = ranker,
        limit = 10,  # å…ˆè·å–æ›´å¤šå€™é€‰ç»“æœï¼Œå†é€šè¿‡é˜ˆå€¼è¿‡æ»¤
        output_fields = ["context_text"],
    )                  # res : [[hit1, hit2, hit3]] 

    # åº”ç”¨å±‚è¿‡æ»¤ï¼šåªä¿ç•™åˆ†æ•° >= min_score çš„ç»“æœ
    # ç”±äºå¯ç”¨äº† norm_score=Trueï¼Œdistance å·²å½’ä¸€åŒ–åˆ° [0, ~1.57] èŒƒå›´ (arctan(âˆ) â‰ˆ Ï€/2)
    # é˜ˆå€¼è®¾ä¸º 0.7ï¼šè€ƒè™‘åˆ°Markdownæ ¼å¼ã€emojiã€ç©ºæ ¼ç­‰å› ç´ å¯èƒ½é™ä½ç›¸ä¼¼åº¦
    # å¯¹äºå†å²å¯¹è¯æ£€ç´¢ï¼Œé€‚å½“æ”¾å®½é˜ˆå€¼å¯ä»¥æé«˜å¬å›ç‡
    filtered_results = [item for item in res[0] if item.distance >= 0.65]
    logger.info(f"âœ… å†å²å¯¹è¯æ£€ç´¢å®Œæˆï¼šæ‰¾åˆ° {len(filtered_results)} æ¡ç›¸å…³è®°å½• (é˜ˆå€¼: 0.65, å½’ä¸€åŒ–å)")

    # å¤„ç†ç»“æœ ä½ æƒ³è¦æ¨¡å‹çœ‹åˆ°ä»€ä¹ˆ context_pieces å°±æ‹¿ hit çš„å“ªä¸ªå­—æ®µ
    context_pieces = []
    for hit in filtered_results:
        context_pieces.append(f"{hit.get('context_text')}")        # åªéœ€è¦æ‹¿åˆ°æ¯ä¸ªhitçš„context_textå­—æ®µ

    return "\n".join(context_pieces) if context_pieces else "no context found"  # è¿”å›æ‹¼æ¥åçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ ä½œä¸ºåç»­æ¨¡å‹å›ç­”å‚è€ƒçš„ä¸Šä¸‹æ–‡



# å·¥å…·åˆ—è¡¨
context_tools = [search_context]  # ä¸Šä¸‹æ–‡æ£€ç´¢å·¥å…·
web_tools = [web_search]  # ç½‘ç»œæœç´¢å·¥å…·
all_tools = [search_context, web_search]  # æ‰€æœ‰å·¥å…·
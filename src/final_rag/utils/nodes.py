import sys
from pathlib import Path
# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent))

from dataclasses import dataclass
import logging
from langchain_core.messages import HumanMessage, ToolMessage
from langchain_core.prompts import ChatPromptTemplate
from langgraph.graph.state import RunnableConfig
from langgraph.runtime import Runtime

from src.final_rag.utils.state import InvalidInputError, MultidalModalRAGState
from src.final_rag.utils.prompt import CONTEXT_SYSTEM_PROMPT, ANSWER_GENERATION_PROMPT, RETRIEVER_GENERATE_SYSTEM_PROMPT
from src.final_rag.utils.tools import  web_tools
from llm_utils import qwen3_vl_plus, qwen3_max
from langchain_core.messages import SystemMessage, AIMessage
from env_utils import COLLECTION_NAME, MILVUS_URI
from milvus_db.milvus_retrieve import MilvusRetriever
from pymilvus import MilvusClient
from utils.embeddings_utils import call_dashscope_once
from ragas import SingleTurnSample
from ragas.metrics import ResponseRelevancy
from langgraph.types import interrupt

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


m_retriever = MilvusRetriever(collection_name=COLLECTION_NAME, milvus_client=MilvusClient(uri=MILVUS_URI, user='root', password='Milvus'))
@dataclass
class UserContext:
    user_name: str

def process_input(state: MultidalModalRAGState, config: RunnableConfig, runtime:Runtime[UserContext]):
    """å¤„ç†ç”¨æˆ·è¾“å…¥
    config: RunnableConfig åŒ…å«é…ç½®ä¿¡æ¯ï¼ˆå¦‚ thread_id ï¼‰å’Œè¿½è¸ªä¿¡æ¯ï¼ˆå¦‚ tags ï¼‰çš„ RunnableConfig å¯¹è±¡ config["configurable"]["thread_id"]
    runtime: Runtime[UserContext] åŒ…å«è¿è¡Œæ—¶ Runtime åŠå…¶ä»–ä¿¡æ¯ï¼ˆå¦‚ context å’Œ store ï¼‰çš„å¯¹è±¡ runtime.context.user_name
    """
    user_name = runtime.context.user_name  # UserContextæ˜¯dataclassï¼Œç›´æ¥è®¿é—®å±æ€§
    last_message = state["messages"][-1]
    
    input_type = 'has_text'
    text_context = None
    image_url = None

    # æ£€æŸ¥è¾“å…¥ç±»å‹
    if isinstance(last_message, HumanMessage):
        if isinstance(last_message.content, list):       # å¤šæ¨¡æ€æ¶ˆæ¯æ˜¯åˆ—è¡¨ æ¯”å¦‚ input = [{'image': 'xxxx', 'text': 'yyyy'}]
            content = last_message.content
            for item in content:
                # æå–æ–‡æœ¬å†…å®¹
                if item.get("type") == "text":
                    text_context = item.get("text", None)
                
                # æå–å›¾ç‰‡URL
                elif item.get("type") == "image_url":
                    url = item.get("image_url", "").get('url')
                    if url:              # å›¾ç‰‡çš„base64æ ¼å¼çš„å­—ç¬¦ä¸² 
                        image_url = url
    
    # æ‰“å°ç®€åŒ–çš„ç”¨æˆ·è¾“å…¥ä¿¡æ¯ï¼ˆä¸åŒ…å« base64 æ•°æ®ï¼‰
    if text_context and image_url:
        logger.info(f"   æ–‡æœ¬å†…å®¹: {text_context[:50]}..." if len(text_context) > 50 else f"   æ–‡æœ¬å†…å®¹: {text_context}")
    elif text_context:
        logger.info(f"ğŸ¤—ä¸»äºº {user_name} å‘é€æ¶ˆæ¯: {text_context}")
    elif image_url:
        logger.info(f"ğŸ¤—ä¸»äºº {user_name} å‘é€æ¶ˆæ¯: [çº¯å›¾ç‰‡]")
    
    else:
        raise InvalidInputError(f"Invalid input type: {type(last_message)}")

    # åˆ¤æ–­è¾“å…¥ç±»å‹
    if text_context and image_url:
        input_type = 'has_text'  # å›¾æ–‡æ··åˆï¼Œä¹Ÿç®—æœ‰æ–‡æœ¬
    elif text_context and not image_url:
        input_type = 'has_text'  # çº¯æ–‡æœ¬
    elif image_url and not text_context:
        input_type = 'only_image'  # çº¯å›¾ç‰‡
    else:
        # æ—¢æ²¡æœ‰æ–‡æœ¬ä¹Ÿæ²¡æœ‰å›¾ç‰‡ï¼Œè¿™æ˜¯é”™è¯¯æƒ…å†µ
        raise InvalidInputError("Input must contain either text or image")
                
    # å¦‚æœæƒ³æŠŠä»€ä¹ˆæ ·çš„æ•°æ®æ›´æ–°åˆ°è‡ªå·±å®šä¹‰çš„çŠ¶æ€ä¸­ï¼Œè¯·è¿”å›ä¸€ä¸ªå­—å…¸ï¼ŒæŒ‰ç…§ä½ è‡ªå·±å®šä¹‰çš„schemaæ¥
    return {
        "input_type": input_type,
        "input_text": text_context,  # ä¿®æ”¹ä¸º input_textï¼Œä¸ state å®šä¹‰ä¸€è‡´
        "input_image": image_url,    # ä¿®æ”¹ä¸º input_imageï¼Œä¸ state å®šä¹‰ä¸€è‡´
        "user": user_name,
    }

#  è‡ªå®šä¹‰æ˜¯ä¸ºäº†æ›¿ä»£ï¼šç”±LangGraphæ¡†æ¶è‡ªå¸¦çš„ToolNodeï¼ˆæœ‰å¤§æ¨¡å‹åŠ¨æ€ä¼ å‚ æ¥è°ƒç”¨å·¥å…·ï¼‰ è¿™ä¸ªå¾ˆå¥½å†™ï¼Œä¸»è¦è¿˜æ˜¯toolçš„é€»è¾‘ 
class SearchContextToolNode:
    """è‡ªå®šä¹‰ç±»ï¼Œæ¥çœŸæ­£æ‰§è¡Œæœç´¢ä¸Šä¸‹æ–‡å·¥å…· é€šè¿‡å¯¹é½ä¸Šä¸€æ¡AIMessageè¿”å›çš„Toolcallå­—æ®µçš„ä¿¡æ¯æ¥è°ƒç”¨å¯¹åº”çš„å·¥å…· tools_by_name[tool_call["name"]].invoke()"""

    def __init__(self, tools: list) -> None:
        self.tools_by_name = {tool.name: tool for tool in tools}

    # inputs å°±æ˜¯è¿™ä¸ª è‡ªå®šä¹‰ state (è‡ªå®šä¹‰schema) çš„å®ä¾‹
    def __call__(self, inputs: dict):
        messages = inputs.get("messages", [])
        if messages:
            message = messages[-1]
        else:
            raise ValueError("No message found in input")
        outputs = []
        for tool_call in message.tool_calls:
            # ä½¿ç”¨LLMæ¨ç†å‡ºçš„args
            tool_args = tool_call["args"].copy()
            
            # åªè¡¥å……LLMæ— æ³•çŸ¥é“çš„user_nameï¼ˆä»runtime contextæ³¨å…¥åˆ°stateä¸­ï¼‰
            if "user_name" not in tool_args or tool_args["user_name"] is None:
                tool_args["user_name"] = inputs.get("user")
            
            tool_result = self.tools_by_name[tool_call["name"]].invoke(tool_args)
            
            outputs.append(
                ToolMessage(
                    content=tool_result,
                    name=tool_call["name"],
                    tool_call_id=tool_call["id"],
                )
            )
        return {"messages": outputs}

# æ£€ç´¢æ•°æ®åº“èŠ‚ç‚¹
def retrieve_database(state: MultidalModalRAGState):
    """
    æ£€ç´¢æ•°æ®åº“èŠ‚ç‚¹
    Args:
        state: MultidalModalRAGState çŠ¶æ€
    """
    if state.get("input_type") == "has_text":
        # æ„å»ºæ–‡æœ¬è¾“å…¥æ•°æ®
        input_data = [{'text': state.get("input_text")}]
        ok, dense_embedding, status, retry_after = call_dashscope_once(input_data)
        results = m_retriever.hybrid_search(dense_embedding, state.get("input_text"), sparse_weight=0.8, dense_weight=1, limit=3)

    else:
        # æ„å»ºå›¾åƒè¾“å…¥æ•°æ®
        input_data = [{'image': state.get("input_image")}]
        ok, dense_embedding, status, retry_after = call_dashscope_once(input_data)      # å›¾åƒä»…æ”¯æŒå¯†é›†å‘é‡æ£€ç´¢çš„æ–¹å¼
        results = m_retriever.dense_search(dense_embedding, limit=3)
    
    # logger.info(f"ä»çŸ¥è¯†æ•°æ®åº“æ£€ç´¢åˆ°çš„ç»“æœä¸º: {results}")

    # è¿”å›æ–‡æ¡£å†…å®¹
    images = []           # å›¾ç‰‡çš„å®é™…è·¯å¾„+å›¾ç‰‡çš„æ‘˜è¦
    docs = []
    # print(results) 
    for hit in results:
        if hit.get('category') == 'image':        # æ ¹æ®æ•°æ®åº“çš„categoryå­—æ®µåˆ¤æ–­æ˜¯å›¾ç‰‡è¿˜æ˜¯æ–‡æœ¬
            images.append({
                'image_path': hit.get('image_path'),
                'image_summary': hit.get('text'),           # æ•°æ®åº“çš„ 'category' çš„'text' å­—æ®µæ˜¯æˆ‘ç»“åˆllmç”Ÿæˆçš„å›¾ç‰‡çš„æ‘˜è¦
                'category': hit.get('category'),
            })
        else:
            docs.append({
                'text': hit.get('text'),
                'category': hit.get('category'),
                'filename': hit.get('filename'),
                'filetype': hit.get('filetype'),
                'image_path': hit.get('image_path'),
                'title': hit.get('title'),
                })
    # æ ¹æ®è‡ªå®šä¹‰çš„stateï¼Œæ”¾å…¥å¯¹åº”çš„ä¿¡æ¯  è¦å•¥æˆ‘å°±è¿”å›å•¥ å¾ˆeasy
    return {"context_retrieved": docs, "images_retrieved": images}


# ç¬¬ä¸€ä¸ªagentå†³ç­–èŠ‚ç‚¹
def first_agent_decision(state: MultidalModalRAGState):
    """
    ç¬¬ä¸€ä¸ªagentå†³ç­–èŠ‚ç‚¹ 
    
    åŠŸèƒ½ï¼š
    - å¯ä»¥è°ƒç”¨ search_contextï¼ˆæ£€ç´¢å†å²å¯¹è¯ï¼‰
    - å¯ä»¥è°ƒç”¨ web_searchï¼ˆç½‘ç»œæœç´¢å®æ—¶ä¿¡æ¯ï¼‰
    - å¯ä»¥ç›´æ¥å›ç­”ç®€å•é—®é¢˜
    
    Args:
        state: MultidalModalRAGState çŠ¶æ€
    Returns:
        å¦‚æœllmå†³å®šè°ƒç”¨å·¥å…· è¿”å›å¸¦æœ‰tool_callå­—æ®µçš„AIMessage
        å¦‚æœllmå†³å®šä¸è°ƒç”¨å·¥å…· è¿”å›ä¸å¸¦æœ‰tool_callå­—æ®µçš„AIMessage
    """
    # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æ˜ç¡®è¦æ±‚æ£€ç´¢ä¸Šä¸‹æ–‡
    user_input = (state.get("input_text") or "").lower()
    explicit_context_keywords = ["æ£€ç´¢ä¸Šä¸‹æ–‡", "æ£€ç´¢å†å²", "search context", "check history", "search my context"]
    
    # å¦‚æœç”¨æˆ·æ˜ç¡®è¦æ±‚æ£€ç´¢ä¸Šä¸‹æ–‡ï¼Œå¼ºåˆ¶è°ƒç”¨ search_context å·¥å…·
    if any(keyword in user_input for keyword in explicit_context_keywords):
        from langchain_core.messages import AIMessage
        # æå–æŸ¥è¯¢å†…å®¹ï¼ˆå»æ‰"æ£€ç´¢ä¸Šä¸‹æ–‡"ç­‰å…³é”®è¯åçš„å†…å®¹ï¼‰
        query = user_input
        for keyword in explicit_context_keywords:
            query = query.replace(keyword, "").strip().strip("ï¼Œ,")
          
        # æ„é€ å¼ºåˆ¶çš„ tool_call
        return {
            'messages': [AIMessage(
                content="",
                tool_calls=[{
                    "name": "search_context",
                    "args": {"query": query},
                    "id": f"forced_search_context_{hash(query)}"
                }]
            )]
        }
    
    # 1.ç»‘å®šæ‰€æœ‰å·¥å…·ç»™llmï¼ˆå†å²ä¸Šä¸‹æ–‡ + ç½‘ç»œæœç´¢ï¼‰
    from src.final_rag.utils.tools import all_tools
    llm_with_tools = qwen3_vl_plus.bind_tools(all_tools)
    return {
        'messages': llm_with_tools.invoke([
            SystemMessage(content=CONTEXT_SYSTEM_PROMPT),
        ] + state["messages"])
    }

# ç¬¬äºŒæ¬¡ç”Ÿæˆå›å¤ï¼ˆåŸºäºæ£€ç´¢å†å²ä¸Šä¸‹æ–‡ ç”Ÿæˆå›å¤, æ£€ç´¢åˆ°çš„å†å²ä¸Šä¸‹æ–‡åœ¨ToolMessageé‡Œé¢ï¼‰
def second_agent_generate(state: MultidalModalRAGState):
    
    """
    ç¬¬äºŒæ¬¡ç”Ÿæˆå›å¤ï¼ˆåŸºäºæ£€ç´¢ç”¨æˆ·å†å²ä¸Šä¸‹æ–‡ ç”Ÿæˆå›å¤, æ£€ç´¢åˆ°çš„ç”¨æˆ·å†å²ä¸Šä¸‹æ–‡åœ¨SearchContextToolNodeå·¥å…·èŠ‚ç‚¹å®ç°çš„ToolMessageé‡Œé¢ï¼‰
    Args:
        state: MultidalModalRAGState çŠ¶æ€
    Returns:
        str: ç¬¬äºŒæ¬¡ç”Ÿæˆå›å¤
    """
    # æ·»åŠ ç³»ç»Ÿæç¤ºè¯ï¼ŒæŒ‡å¯¼æ¨¡å‹å¦‚ä½•åŸºäºæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ç”Ÿæˆå›å¤
    messages_with_prompt = [SystemMessage(content=ANSWER_GENERATION_PROMPT)] + state["messages"]
    return {'messages': [qwen3_vl_plus.invoke(messages_with_prompt)]}

# ç¬¬ä¸‰æ¬¡å›å¤ (åŸºäºä»çŸ¥è¯†åº“çš„ä¸Šä¸‹æ–‡ è¿›è¡Œå›å¤ markdownæ ¼å¼è¾“å‡ºï¼Œå› ä¸ºæ—¢æœ‰å›¾ç‰‡ä¹Ÿæœ‰æ–‡å­—ï¼Œå›¾ç‰‡ç”¨markdownè¯­æ³•å±•ç¤º æ£€ç´¢åˆ°çš„ç»“æœåœ¨çŠ¶æ€é‡Œé¢)
def third_chatbot(state: MultidalModalRAGState):
    """
    å¤„ç†å¤šæ¨¡æ€è¯·æ±‚å¹¶è¿”å›Markdownæ ¼å¼çš„ç»“æœ
    """
    context_retrieved = state.get("context_retrieved", [])
    images_retrieved = state.get("images_retrieved", [])

    # æ ¼å¼åŒ–å¤„ç†æ–‡æœ¬å†…å®¹çš„ä¸Šä¸‹æ–‡
    count = 0
    context_pieces = []
    for hit in context_retrieved:
        count += 1
        context_pieces.append(f"\nä¸Šä¸‹æ–‡{count}:\n {hit.get('text')} \n èµ„æ–™æ¥æº: {hit.get('filename')}")
    context = "\n".join(context_pieces) if context_pieces else "no context found"         # æ„å»ºæ£€ç´¢åˆ°çš„æœ€ç»ˆæ–‡æœ¬ä¸Šä¸‹æ–‡

    # æ ¼å¼åŒ–å¤„ç†å›¾ç‰‡å†…å®¹çš„ä¸Šä¸‹æ–‡
    image_count = 0
    image_pieces = []
    for image in images_retrieved:
        image_count += 1
        image_pieces.append(f"\nå›¾ç‰‡{image_count}:\n {image.get('image_summary')} \n èµ„æ–™æ¥æº: {image.get('image_path')}")
    images = "\n".join(image_pieces) if image_pieces else "no image found"         # æ„å»ºæ£€ç´¢åˆ°çš„æœ€ç»ˆå›¾ç‰‡ä¸Šä¸‹æ–‡

    input_text = state.get("input_text", "")
    input_image = state.get("input_image", "")

    # æ„å»ºç”¨æˆ·æ¶ˆæ¯
    user_content = []
    if input_text:
        user_content.append({'type': 'text', 'text': input_text})
    if input_image:
        # input_image å·²ç»æ˜¯å®Œæ•´çš„ base64 URL å­—ç¬¦ä¸²ï¼Œéœ€è¦åŒ…è£…æˆæ­£ç¡®çš„æ ¼å¼
        user_content.append({'type': 'image_url', 'image_url': {'url': input_image}})

    # æç¤ºè¯çš„æ’°å†™éœ€è¦å‚è€ƒä½ æ ¼å¼åŒ–ä¹‹åä¼ å…¥çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œç”¨å¥½è¿™äº›ä¿¡æ¯è¾¾åˆ°ä½ çš„ç›®çš„
    prompt = ChatPromptTemplate.from_messages([
        ('system', RETRIEVER_GENERATE_SYSTEM_PROMPT),
        ('user', user_content),
    ])

    chain = prompt | qwen3_vl_plus

    response = chain.invoke({'context': context, 'images': images})   # æŠŠæ ¼å¼åŒ–å¥½çš„æ–‡æœ¬ä»¥åŠå›¾ç‰‡ä¸Šä¸‹æ–‡ä¼ å…¥åˆ°æç¤ºè¯ä¸­

    return {'messages': [response]}

# è¯„ä¼°èŠ‚ç‚¹
async def evaluate_node(state: MultidalModalRAGState):
    """è¯„ä¼°å¤§æ¨¡å‹çš„å“åº”å’Œç”¨æˆ·è¾“å…¥ä¹‹é—´çš„ç›¸å…³æ€§"""
    context_retrieved = state.get("context_retrieved", [])
    input_text = state.get("input_text", "")
    last_message = state["messages"][-1]      # å¤§æ¨¡å‹çš„å“åº”
    if isinstance(last_message, AIMessage):
        answer = last_message.content         # æ‹¿åˆ°æ£€ç´¢ç”ŸæˆèŠ‚ç‚¹ç”Ÿæˆçš„æ–‡å­—å›ç­”
    
    # 1.åˆ›å»ºè¯„ä¼°æ ·æœ¬SingleTurnSample
    sample = SingleTurnSample(
        user_input=input_text,          # ç”¨æˆ·è¾“å…¥çš„é—®é¢˜
        retrieved_contexts=[f"ä¸Šä¸‹æ–‡{i+1}: {context['text']}" for i, context in enumerate(context_retrieved)],    # æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ text å­—æ®µæ˜¯æˆ‘ä»¬éœ€è¦çš„
        response=answer,            # RAGæ¨¡å‹ç”Ÿæˆçš„ç­”æ¡ˆ
    )
    # 2.åˆ›å»ºè¯„ä¼°æŒ‡æ ‡
    # å“åº”ç›¸å…³æ€§è¯„ä¼°æŒ‡æ ‡ - éœ€è¦åŒæ—¶æä¾› LLM å’Œ embeddings
    from llm_utils import qwen_embeddings  # å¯¼å…¥embeddings
    response_relevancy = ResponseRelevancy(llm=qwen3_max, embeddings=qwen_embeddings)
    # æ£€ç´¢å†…å®¹ ä¸Šä¸‹æ–‡å‡†ç¡®åº¦è¯„ä¼°æŒ‡æ ‡
    # retrieved_context_precision = LLMContextPrecision(llm=qwen3_max)
            
    # 3.è¯„ä¼°
    context_precision_score = await response_relevancy.single_turn_ascore(sample)
    score_value = float(context_precision_score)
    
    # è¾“å‡ºè¯„ä¼°ç»“æœï¼ˆå¸¦é˜ˆå€¼å¯¹æ¯”ï¼‰
    threshold = 0.75
    if score_value >= threshold:
        logger.info(f"âœ… è¯„ä¼°å®Œæˆ - åˆ†æ•°: {score_value:.3f} (>= é˜ˆå€¼ {threshold}) - è´¨é‡åˆæ ¼")
    else:
        logger.info(f"âš ï¸  è¯„ä¼°å®Œæˆ - åˆ†æ•°: {score_value:.3f} (< é˜ˆå€¼ {threshold}) - éœ€è¦äººå·¥å®¡æ ¸")
    
    return {'evaluate_score': score_value}

# äººå·¥å®¡æ ¸èŠ‚ç‚¹
def human_approval_node(state: MultidalModalRAGState):
    """
    äººå·¥å®¡æ ¸èŠ‚ç‚¹
    å½“è¯„ä¼°åˆ†æ•°ä½äºé˜ˆå€¼æ—¶ï¼Œæš‚åœæ‰§è¡Œå¹¶è¯·æ±‚äººå·¥å®¡æ ¸
    
    ä½¿ç”¨æ–¹å¼ï¼š
    1. é¦–æ¬¡æ‰§è¡Œæ—¶è§¦å‘ interruptï¼Œæš‚åœå¹¶ç­‰å¾…äººå·¥å®¡æ ¸
    2. æ¢å¤æ‰§è¡Œæ—¶ï¼Œä¼ å…¥çš„ Command(resume=decision) ä¸­çš„ decision ä¼šæˆä¸º interrupt çš„è¿”å›å€¼
    3. æ ¹æ®å®¡æ ¸ç»“æœæ›´æ–°çŠ¶æ€
    
    æ³¨æ„ï¼š
    - interrupt() å¿…é¡»è¿”å› JSON å¯åºåˆ—åŒ–çš„å€¼
    - æ¢å¤æ—¶èŠ‚ç‚¹ä¼šä»å¤´é‡æ–°æ‰§è¡Œï¼Œinterrupt() å‰çš„ä»£ç ä¼šå†æ¬¡è¿è¡Œï¼ˆéœ€ä¿è¯å¹‚ç­‰æ€§ï¼‰
    - ä¸è¦åœ¨ try/except ä¸­åŒ…è£¹ interrupt() è°ƒç”¨
    """
    # æå–å½“å‰å“åº”å†…å®¹
    last_message = state.get("messages", [])[-1] if state.get("messages") else None
    response_content = last_message.content if last_message else "No response available"
    
    # æš‚åœæ‰§è¡Œï¼Œè¯·æ±‚äººå·¥å®¡æ ¸
    # è¿™é‡Œä¼ é€’çš„å­—å…¸ä¼šåœ¨è°ƒç”¨è€…ç«¯ä»¥ __interrupt__ å­—æ®µè¿”å›
    is_approved = interrupt({
        "question": "æ˜¯å¦æ‰¹å‡†æ­¤å›ç­”ï¼Ÿ",     # å‘Šè¯‰è°ƒç”¨è€…ï¼šæˆ‘åœ¨é—®ä»€ä¹ˆ
        "score": state.get("evaluate_score"),  # æä¾›å†³ç­–ä¾æ®ï¼šè¯„åˆ†æ˜¯å¤šå°‘
        "response": response_content[:50],          # æä¾›å†³ç­–ä¾æ®ï¼šå›ç­”å†…å®¹æ˜¯ä»€ä¹ˆ
        "user_input": state.get("input_text"), # æä¾›ä¸Šä¸‹æ–‡ï¼šç”¨æˆ·é—®çš„æ˜¯ä»€ä¹ˆ
        "timestamp": "evaluation_pending"      # å…¶ä»–å…ƒä¿¡æ¯
    })
    # å½“å›¾æ¢å¤æ‰§è¡Œæ—¶ï¼Œis_approved ä¼šæ˜¯ Command(resume=xxx) ä¸­ä¼ å…¥çš„å€¼
    # æ›´æ–°çŠ¶æ€ä¸­çš„å®¡æ ¸ç»“æœ
    logger.info(f"äººå·¥å®¡æ ¸ç»“æœ: {'æ‰¹å‡†' if is_approved else 'æ‹’ç»'}")
    # æ›´æ–°äººå·¥å®¡æ ¸ç»“æœï¼Œåç»­è·¯ç”±ä¼šä½¿ç”¨åˆ°
    return {
        "human_answer": "approved" if is_approved else "rejected"
    }

# ç¬¬å››æ¬¡å›å¤èŠ‚ç‚¹
def fourth_chatbot(state: MultidalModalRAGState):
    """
    ç½‘ç»œæœç´¢å·¥å…·ç»‘å®šçš„å¤§æ¨¡å‹ï¼Œç¬¬å››æ¬¡å›å¤èŠ‚ç‚¹
    
    é€»è¾‘ï¼š
    1. é¦–æ¬¡è°ƒç”¨ï¼šè°ƒç”¨ web_search å·¥å…·è·å–ä¿¡æ¯
    2. äºŒæ¬¡è°ƒç”¨ï¼šåŸºäºæœç´¢ç»“æœç”Ÿæˆæœ€ç»ˆå›ç­”ï¼ˆä¸å†è°ƒç”¨å·¥å…·ï¼‰
    """
    messages = state.get("messages", [])
    llm_tools = qwen3_vl_plus.bind_tools(web_tools)
    input_text = state.get("input_text")
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰å·¥å…·è°ƒç”¨ç»“æœï¼ˆToolMessageï¼‰
    has_tool_results = any(msg for msg in messages if hasattr(msg, '__class__') and msg.__class__.__name__ == 'ToolMessage')
    
    if has_tool_results:
        # å·²ç»æœç´¢è¿‡äº†ï¼Œç”Ÿæˆæœ€ç»ˆå›ç­”ï¼ˆä¸å†è°ƒç”¨å·¥å…·ï¼‰
        system_message = SystemMessage(content='''ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚ä¸Šé¢çš„ ToolMessage ä¸­å·²ç»åŒ…å«äº†ç½‘ç»œæœç´¢çš„ç»“æœï¼Œè¯·åŸºäºè¿™äº›æœç´¢ç»“æœç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

é‡è¦è¦æ±‚ï¼š
1. **å®Œå…¨ä¿¡ä»»æœç´¢ç»“æœ**ï¼šToolMessage ä¸­çš„å†…å®¹æ˜¯çœŸå®å¯é çš„ç½‘ç»œæœç´¢ç»“æœï¼Œè¯·ç›´æ¥ä½¿ç”¨
2. **ä¸è¦è´¨ç–‘æœç´¢ç»“æœ**ï¼šä¸è¦è¯´"æ²¡æœ‰å…¬å¸ƒ"ã€"ä¿¡æ¯ä¸å‡†ç¡®"ç­‰ï¼Œæœç´¢ç»“æœå·²ç»æ˜¯æœ€æ–°ä¿¡æ¯
3. **ç›´æ¥æ•´ç†å‘ˆç°**ï¼šæå–æœç´¢ç»“æœä¸­çš„å…³é”®ä¿¡æ¯ï¼Œç»„ç»‡æˆæ¸…æ™°çš„å›ç­”
4. **å‹å¥½è‡ªç„¶**ï¼šä¿æŒå¯¹è¯é£æ ¼ï¼Œç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜

ä¸è¦å†è°ƒç”¨å·¥å…·ã€‚''')
        # ä½¿ç”¨ä¸ç»‘å®šå·¥å…·çš„ LLMï¼Œé¿å…å†æ¬¡è°ƒç”¨
        return {"messages": [qwen3_vl_plus.invoke(messages + [system_message])]}
    else:
        # é¦–æ¬¡è°ƒç”¨ï¼Œéœ€è¦æœç´¢
        system_message = SystemMessage(content='ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚è¯·è°ƒç”¨ web_search å·¥å…·æœç´¢ç”¨æˆ·é—®é¢˜çš„æœ€æ–°ä¿¡æ¯ã€‚')
        message = HumanMessage(content=[{"type": "text", "text": input_text}])
        return {"messages": [llm_tools.invoke([system_message, message])]}


# æ‘˜è¦èŠ‚ç‚¹
async def summarize_if_needed(state: MultidalModalRAGState):
    """
    æ¡ä»¶æ‘˜è¦èŠ‚ç‚¹ï¼šå½“æ¶ˆæ¯æ•°é‡è¶…è¿‡é˜ˆå€¼æ—¶è‡ªåŠ¨ç”Ÿæˆæ‘˜è¦
    
    åŠŸèƒ½ï¼š
    1. æ£€æŸ¥æ¶ˆæ¯æ•°é‡æ˜¯å¦è¶…è¿‡é˜ˆå€¼ï¼ˆé»˜è®¤25æ¡ï¼Œé€‚åº”å¤šAgentå¤æ‚å·¥ä½œæµï¼‰
    2. å¦‚æœè¶…è¿‡ï¼Œè°ƒç”¨LLMç”Ÿæˆæˆ–æ›´æ–°æ‘˜è¦
    3. æ™ºèƒ½ä¿ç•™ç­–ç•¥ï¼šä¿ç•™ä»æœ€åä¸€ä¸ªç”¨æˆ·æ¶ˆæ¯å¼€å§‹çš„å®Œæ•´å¯¹è¯è½®æ¬¡
    4. å°†æ‘˜è¦ä¿¡æ¯æŒä¹…åŒ–åˆ°stateä¸­
    
    æ‘˜è¦ç­–ç•¥ï¼š
    - å¦‚æœå·²æœ‰æ‘˜è¦ï¼Œåˆ™åŸºäºæ—§æ‘˜è¦ + æœ€è¿‘æ¶ˆæ¯ç”Ÿæˆå¢é‡æ‘˜è¦
    - å¦‚æœæ²¡æœ‰æ‘˜è¦ï¼Œåˆ™å¯¹æ‰€æœ‰æ¶ˆæ¯ç”Ÿæˆæ–°æ‘˜è¦
    
    ä¿ç•™ç­–ç•¥ï¼š
    - æ™ºèƒ½æ¨¡å¼ï¼šä»æœ€åä¸€ä¸ª HumanMessage å¼€å§‹ä¿ç•™æ‰€æœ‰åç»­æ¶ˆæ¯ï¼ˆä¿è¯å®Œæ•´å¯¹è¯è½®æ¬¡ï¼‰
    - é™çº§æ¨¡å¼ï¼šå¦‚æœæ‰¾ä¸åˆ° HumanMessageï¼Œä¿ç•™æœ€è¿‘8æ¡æ¶ˆæ¯
    
    Args:
        state: MultidalModalRAGState çŠ¶æ€å¯¹è±¡
        
    Returns:
        dict: åŒ…å«æ›´æ–°åçš„ summaryã€messagesï¼ˆåˆ é™¤æŒ‡ä»¤ï¼‰å’Œ message_count
    """
    from langchain_core.messages import RemoveMessage
    
    messages = state.get("messages", [])
    current_count = len(messages)
    threshold = 20  # æ¶ˆæ¯æ•°é‡é˜ˆå€¼ï¼ˆå¯æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼‰
    
    logger.info(f"ğŸ“Š æ‘˜è¦æ£€æŸ¥ - å½“å‰æ¶ˆæ¯æ•°: {current_count}, é˜ˆå€¼: {threshold}")
    
    # å¦‚æœæ¶ˆæ¯æ•°é‡æœªè¶…è¿‡é˜ˆå€¼ï¼Œè·³è¿‡æ‘˜è¦ç”Ÿæˆ
    if current_count <= threshold:
        logger.info(f"âœ… æ¶ˆæ¯æ•°é‡æœªè¶…è¿‡é˜ˆå€¼ï¼Œè·³è¿‡æ‘˜è¦ç”Ÿæˆ")
        return {"message_count": current_count}
    
    logger.info(f"âš ï¸ æ¶ˆæ¯æ•°é‡è¶…è¿‡é˜ˆå€¼ï¼Œå¼€å§‹ç”Ÿæˆæ‘˜è¦...")
    
    # è·å–ç°æœ‰æ‘˜è¦
    existing_summary = state.get("summary", "")
    
    # æ„å»ºæ‘˜è¦æç¤ºè¯
    if existing_summary:
        # å·²æœ‰æ‘˜è¦ï¼Œç”Ÿæˆå¢é‡æ‘˜è¦ï¼ˆåŸºäºæ—§æ‘˜è¦ + æœ€è¿‘5æ¡æ¶ˆæ¯ï¼‰ 
        recent_messages = messages[-5:]
        recent_messages_text = "\n".join([
            f"- {msg.__class__.__name__}: {msg.content[:400]}..." 
            if len(str(msg.content)) > 400 else f"- {msg.__class__.__name__}: {msg.content}"
            for msg in recent_messages   # éå† recent_messages ä¸­çš„æ¯ä¸€æ¡æ¶ˆæ¯ msgï¼Œå¯¹å®ƒåšå¤„ç†ï¼Œç”Ÿæˆä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œæœ€åç»„æˆä¸€ä¸ªåˆ—è¡¨ã€‚
        ])
        
        summary_prompt = f"""ä½ æ˜¯ä¸€ä¸ªå¯¹è¯æ‘˜è¦åŠ©æ‰‹ã€‚è¯·æ›´æ–°ä»¥ä¸‹å¯¹è¯æ‘˜è¦ã€‚

ã€ä¹‹å‰çš„æ‘˜è¦ã€‘
{existing_summary}

ã€æœ€æ–°çš„å¯¹è¯ï¼ˆæœ€è¿‘5æ¡æ¶ˆæ¯ï¼‰ã€‘
{recent_messages_text}

ã€è¦æ±‚ã€‘
1. ä¿ç•™ä¹‹å‰æ‘˜è¦ä¸­çš„å…³é”®ä¿¡æ¯
2. æ•´åˆæœ€æ–°å¯¹è¯çš„é‡è¦å†…å®¹
3. ä¿æŒæ‘˜è¦ç®€æ´ï¼ˆä¸è¶…è¿‡500å­—ï¼‰
4. çªå‡ºç”¨æˆ·çš„é—®é¢˜å’Œç³»ç»Ÿçš„å…³é”®å›ç­”
5. åªè¿”å›æ‘˜è¦å†…å®¹ï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–è¯´æ˜

è¯·ç”Ÿæˆæ›´æ–°åçš„æ‘˜è¦ï¼š"""
    else:
        # é¦–æ¬¡ç”Ÿæˆæ‘˜è¦ï¼ŒåŸºäºæ‰€æœ‰æ¶ˆæ¯
        all_messages_text = "\n".join([
            f"- {msg.__class__.__name__}: {msg.content[:500]}..." 
            if len(str(msg.content)) > 500 else f"- {msg.__class__.__name__}: {msg.content}"
            for msg in messages
        ])
        
        summary_prompt = f"""ä½ æ˜¯ä¸€ä¸ªå¯¹è¯æ‘˜è¦åŠ©æ‰‹ã€‚è¯·ä¸ºä»¥ä¸‹å¯¹è¯ç”Ÿæˆç®€æ´çš„æ‘˜è¦ã€‚

ã€å®Œæ•´å¯¹è¯å†å²ã€‘
{all_messages_text}

ã€è¦æ±‚ã€‘
1. æå–å¯¹è¯çš„æ ¸å¿ƒä¸»é¢˜å’Œå…³é”®ä¿¡æ¯
2. ä¿ç•™ç”¨æˆ·çš„ä¸»è¦é—®é¢˜å’Œç³»ç»Ÿçš„å…³é”®å›ç­”
3. ä¿æŒæ‘˜è¦ç®€æ´ï¼ˆä¸è¶…è¿‡500å­—ï¼‰
4. åªè¿”å›æ‘˜è¦å†…å®¹ï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–è¯´æ˜

è¯·ç”Ÿæˆæ‘˜è¦ï¼š"""
    
    # è°ƒç”¨LLMç”Ÿæˆæ‘˜è¦ï¼ˆä½¿ç”¨ qwen3_max è·å¾—æ›´å¥½çš„æ‘˜è¦è´¨é‡ï¼‰
    try:
        summary_message = HumanMessage(content=summary_prompt)
        summary_response = await qwen3_max.ainvoke([summary_message])
        new_summary = summary_response.content
        
        logger.info(f"âœ… æ‘˜è¦ç”ŸæˆæˆåŠŸ - é•¿åº¦: {len(new_summary)} å­—ç¬¦")
        logger.info(f"ğŸ“ æ‘˜è¦å†…å®¹: {new_summary[:100]}..." if len(new_summary) > 100 else f"ğŸ“ æ‘˜è¦å†…å®¹: {new_summary}")
        
    except Exception as e:
        logger.error(f"âŒ æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
        # å¦‚æœæ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œä¿ç•™åŸæœ‰çŠ¶æ€ï¼Œä¸åˆ é™¤æ¶ˆæ¯
        return {"message_count": current_count}
    
    # ğŸ”¥ æ™ºèƒ½ä¿ç•™ç­–ç•¥ï¼šæ‰¾åˆ°æœ€åä¸€ä¸ª HumanMessage çš„ä½ç½®
    # ç›®æ ‡ï¼šä¿ç•™ä»æœ€åä¸€ä¸ªç”¨æˆ·æé—®å¼€å§‹çš„å®Œæ•´å¯¹è¯è½®æ¬¡
    last_human_index = None
    for i in range(len(messages) - 1, -1, -1):  # ä»åå¾€å‰éå†
        if isinstance(messages[i], HumanMessage):
            last_human_index = i
            break  # æ‰¾åˆ°ç¬¬ä¸€ä¸ªï¼ˆä»åå¾€å‰ï¼‰å°±åœæ­¢
    
    if last_human_index is not None and last_human_index > 0:
        # æ‰¾åˆ°äº†ç”¨æˆ·æ¶ˆæ¯ï¼Œä¿ç•™ä»è¯¥ä½ç½®å¼€å§‹çš„æ‰€æœ‰æ¶ˆæ¯ï¼ˆå®Œæ•´å¯¹è¯è½®æ¬¡ï¼‰
        messages_to_keep_count = len(messages) - last_human_index
        messages_to_remove = messages[:last_human_index]
        
        logger.info(f"ğŸ¯ æ‰¾åˆ°æœ€åçš„ç”¨æˆ·æ¶ˆæ¯ä½ç½®: ç´¢å¼• {last_human_index}")
        logger.info(f"ğŸ“¦ ä¿ç•™å®Œæ•´å¯¹è¯è½®æ¬¡: ä»ç´¢å¼• {last_human_index} åˆ° {len(messages)-1}ï¼Œå…± {messages_to_keep_count} æ¡æ¶ˆæ¯")
    else:
        # é™çº§æ–¹æ¡ˆï¼šå¦‚æœæ‰¾ä¸åˆ° HumanMessageï¼ˆç†è®ºä¸Šä¸åº”è¯¥å‘ç”Ÿï¼‰ï¼Œä¿ç•™æœ€è¿‘8æ¡
        messages_to_keep_count = min(8, current_count)
        messages_to_remove = messages[:-messages_to_keep_count] if messages_to_keep_count > 0 else []
        
        logger.info(f"âš ï¸ æœªæ‰¾åˆ°ç”¨æˆ·æ¶ˆæ¯ï¼ˆæˆ–ç”¨æˆ·æ¶ˆæ¯åœ¨é¦–ä½ï¼‰ï¼Œä½¿ç”¨é™çº§ç­–ç•¥ä¿ç•™æœ€è¿‘ {messages_to_keep_count} æ¡")
    
    # ç”Ÿæˆåˆ é™¤æŒ‡ä»¤
    remove_message_objects = [
        RemoveMessage(id=msg.id) for msg in messages_to_remove 
        if hasattr(msg, 'id') and msg.id
    ]
    
    
    # è¿”å›æ›´æ–°åçš„çŠ¶æ€
    return {
        "summary": new_summary,                    # æ›´æ–°æ‘˜è¦
        "messages": remove_message_objects,        # åˆ é™¤æ—§æ¶ˆæ¯çš„æŒ‡ä»¤
        "message_count": messages_to_keep_count    # æ›´æ–°æ¶ˆæ¯è®¡æ•°
    }


